{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8738da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,shutil,scipy,cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torchvision import models, transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81566c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"../raw/images/Images\"\n",
    "\n",
    "\n",
    "TESTSPLIT = 0.2\n",
    "\n",
    "classes = len(os.listdir(img_dir)) # 120\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4096fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_directory(img_dir):\n",
    "    data = []\n",
    "    for breed in os.listdir(img_dir):\n",
    "        breed_path = os.path.join(img_dir, breed)\n",
    "        for image in os.listdir(breed_path):\n",
    "            image_path = os.path.join(breed_path, image)\n",
    "            race = \"_\".join(breed.split('-')[1:])\n",
    "            \n",
    "            data.append([image_path, race])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['image_path', 'breed'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0643ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_breed = {}\n",
    "for breed in os.listdir(img_dir):\n",
    "    breed_path = os.path.join(img_dir, breed)\n",
    "    race = \"_\".join(breed.split('-')[1:])\n",
    "    race = \" \".join(race.split('_'))\n",
    "    race = race.lower()\n",
    "    folder_to_breed[breed] = race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81962e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_directory(img_dir)\n",
    "df = shuffle(df, random_state=42)\n",
    "train_df, val_df = train_test_split(df, test_size=TESTSPLIT, stratify=df['breed'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546b36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e906b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224 # of images\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aecaad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "train_dataset = datasets.ImageFolder(img_dir, data_transforms['train'], is_valid_file=lambda x: x in train_df['image_path'].values)\n",
    "train_dataset.class_to_idx = {folder_to_breed[k]: v for k, v in train_dataset.class_to_idx.items()}\n",
    "\n",
    "val_dataset = datasets.ImageFolder(img_dir, data_transforms['val'], is_valid_file=lambda x: x in val_df['image_path'].values)\n",
    "val_dataset.class_to_idx = {folder_to_breed[k]: v for k, v in val_dataset.class_to_idx.items()}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True, \n",
    "                        ),\n",
    "    'val': DataLoader(  val_dataset, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False, \n",
    "                        ),\n",
    "}\n",
    "\n",
    "dataset_sizes = {'train': len(train_dataset), \n",
    "                 'val': len(val_dataset)}\n",
    "\n",
    "class_names = [folder_to_breed[folder_name] for folder_name in sorted(os.listdir(img_dir))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91eea4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=EPOCHS, verbose=True):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    if verbose:\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc9b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}, actual: {class_names[labels[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49bd1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_traing(torch_model=torchvision.models.resnet50, \n",
    "                freeze_layers=True, num_classes=len(class_names), \n",
    "                num_epochs=EPOCHS, \n",
    "                lr=0.001, \n",
    "                momentum=0.9, \n",
    "                step_size=7, \n",
    "                gamma=0.1,\n",
    "                verbose=True):\n",
    "    \n",
    "    model_ft = torch_model(weights='DEFAULT')\n",
    "    \n",
    "    if freeze_layers:\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model_ft.fc.in_features # number of fully connected layer input features (last layer)\n",
    "\n",
    "    # keep the same number of inputs, but change the number of outputs to the number of classes in our dataset\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes) # fc = fully connected layer, in efficientnet it's called classifier\n",
    "\n",
    "    model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                           num_epochs=num_epochs, verbose=verbose)\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01076a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_freezing_layers = False\n",
    "if compare_freezing_layers:\n",
    "    since = time.time()\n",
    "    model_frozen = init_traing(freeze_layers=True, num_epochs=1, verbose=False)\n",
    "    time_elapsed1 = time.time() - since\n",
    "    print(f\"Time when frozen: {round(time_elapsed1, 2)} seconds\\n\")\n",
    "    \n",
    "    since = time.time()\n",
    "    model_not_frozen = init_traing(freeze_layers=False, num_epochs=1, verbose=False)\n",
    "    time_elapsed2 = time.time() - since\n",
    "    print(f\"Time when not frozen: {round(time_elapsed2, 2)} seconds\\n\")\n",
    "\n",
    "    \n",
    "    print(\"Speedup when freezing layers:\", time_elapsed2/time_elapsed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41707e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 3.6398 Acc: 0.5024\n",
      "val Loss: 2.5101 Acc: 0.7835\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 2.0214 Acc: 0.7547\n",
      "val Loss: 1.4112 Acc: 0.8333\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 1.3326 Acc: 0.8089\n",
      "val Loss: 0.9257 Acc: 0.8632\n",
      "\n",
      "Training complete in 11m 3s\n",
      "Best val Acc: 0.863217\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_train:\n\u001b[32m      3\u001b[39m     model_finetuned = init_traing(freeze_layers=\u001b[38;5;28;01mTrue\u001b[39;00m, num_epochs=EPOCHS, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mvisualize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_finetuned\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     plt.ioff()\n\u001b[32m      9\u001b[39m     plt.show()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mvisualize_model\u001b[39m\u001b[34m(model, num_images)\u001b[39m\n\u001b[32m      3\u001b[39m model.eval()\n\u001b[32m      4\u001b[39m images_so_far = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m fig = \u001b[43mplt\u001b[49m.figure()\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloaders[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m]):\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "start_train = True\n",
    "if start_train:\n",
    "    model_finetuned = init_traing(freeze_layers=True, num_epochs=EPOCHS, verbose=True)\n",
    "    \n",
    "    \n",
    "    visualize_model(model_finetuned)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd16ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_finetuned.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccf901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def evaluate_model_grid(model, dataloader, class_names, device, num_images=64):\n",
    "    \"\"\"\n",
    "    Hiển thị grid 8x8 ảnh với nhãn thật và nhãn dự đoán\n",
    "    \n",
    "    Args:\n",
    "        model: Model đã train\n",
    "        dataloader: DataLoader (val hoặc test)\n",
    "        class_names: List tên các class\n",
    "        device: Device (cuda/cpu)\n",
    "        num_images: Số lượng ảnh hiển thị (mặc định 64 = 8x8)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Lấy ngẫu nhiên các ảnh từ dataloader\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Lưu lại\n",
    "            all_images.extend(inputs.cpu())\n",
    "            all_labels.extend(labels.cpu())\n",
    "            all_preds.extend(preds.cpu())\n",
    "            \n",
    "            # Dừng khi đủ ảnh\n",
    "            if len(all_images) >= num_images:\n",
    "                break\n",
    "    \n",
    "    # Chọn ngẫu nhiên num_images ảnh\n",
    "    indices = random.sample(range(len(all_images)), min(num_images, len(all_images)))\n",
    "    \n",
    "    # Tạo figure 8x8\n",
    "    rows, cols = 8, 8\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "    fig.suptitle('Model Evaluation: Predicted vs Actual Labels', fontsize=20, y=0.995)\n",
    "    \n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < len(indices):\n",
    "            img_idx = indices[idx]\n",
    "            img = all_images[img_idx]\n",
    "            true_label = all_labels[img_idx].item()\n",
    "            pred_label = all_preds[img_idx].item()\n",
    "            \n",
    "            # Denormalize ảnh\n",
    "            img = img.numpy().transpose((1, 2, 0))\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            img = std * img + mean\n",
    "            img = np.clip(img, 0, 1)\n",
    "            \n",
    "            # Hiển thị ảnh\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Tạo title với màu sắc\n",
    "            is_correct = (true_label == pred_label)\n",
    "            color = 'green' if is_correct else 'red'\n",
    "            \n",
    "            # Title: Pred / True\n",
    "            title = f\"Pred: {class_names[pred_label][:15]}\\nTrue: {class_names[true_label][:15]}\"\n",
    "            ax.set_title(title, fontsize=8, color=color, weight='bold')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Tính accuracy\n",
    "    correct = sum([1 for i in indices if all_preds[i] == all_labels[i]])\n",
    "    accuracy = correct / len(indices) * 100\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Accuracy trên {len(indices)} ảnh: {accuracy:.2f}%\")\n",
    "    print(f\"Số ảnh dự đoán đúng: {correct}/{len(indices)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Sử dụng hàm\n",
    "# Đảm bảo đã import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gọi hàm với model đã train\n",
    "evaluate_model_grid(\n",
    "    model=model_finetuned,  # Model của bạn\n",
    "    dataloader=dataloaders['val'],  # Validation dataloader\n",
    "    class_names=class_names,  # List tên class\n",
    "    device=DEVICE,  # Device\n",
    "    num_images=64  # 8x8 = 64 ảnh\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
